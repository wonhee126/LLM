# movie_chatbot_app.py

import streamlit as st
import pandas as pd
import chromadb
import openai
import os
import sys
import time

# API í‚¤ ì„¤ì • (api_setting.pyì—ì„œ ì„í¬íŠ¸)
try:
    current_script_dir = os.path.dirname(os.path.abspath(__file__))
    if current_script_dir not in sys.path:
        sys.path.append(current_script_dir)
        
    from api_setting import OPENAI_API_KEY
    openai.api_key = OPENAI_API_KEY
    print("OpenAI API í‚¤ ì„¤ì • ì™„ë£Œ!")
except ImportError:
    st.error("ì˜¤ë¥˜: 'api_setting.py'ì—ì„œ 'OPENAI_API_KEY'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.error("ìŠ¤í¬ë¦½íŠ¸ì™€ api_setting.pyê°€ ê°™ì€ í´ë”ì— ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , api_setting.pyì— OPENAI_API_KEYê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop() # Streamlit ì•± ì¤‘ì§€
except Exception as e:
    st.error(f"API í‚¤ ì„¤ì • ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ ë°œìƒ: {e}")
    st.stop() # Streamlit ì•± ì¤‘ì§€

# ì„¤ì • ë³€ìˆ˜
CHROMA_DB_PERSIST_PATH = './chroma_db_movies'
CHROMA_COLLECTION_NAME = 'movie_embeddings_collection'

OPENAI_EMBEDDING_MODEL = "text-embedding-3-small" 
GPT_MODEL = "gpt-4o-mini" # ì±—ë´‡ ë‹µë³€ ìƒì„±ì— ì‚¬ìš©í•  GPT ëª¨ë¸

# ChromaDB ë¡œë“œ ë° ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸° (ì´ˆê¸° ë¡œë“œ)
@st.cache_resource # Streamlit ì•± ì‹¤í–‰ ì¤‘ í•œ ë²ˆë§Œ ë¡œë“œí•˜ë„ë¡ ìºì‹±
def load_chroma_collection():
    try:
        client = chromadb.PersistentClient(path=CHROMA_DB_PERSIST_PATH)
        collection = client.get_collection(name=CHROMA_COLLECTION_NAME)
        # st.success(f"ChromaDB ì»¬ë ‰ì…˜ '{CHROMA_COLLECTION_NAME}' ë¡œë“œ ì™„ë£Œ! (ì´ {collection.count()}ê°œ ì•„ì´í…œ)") # ì£¼ì„ ì²˜ë¦¬
        return collection
    except Exception as e:
        st.error(f"ì˜¤ë¥˜: ChromaDB ì»¬ë ‰ì…˜ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. '{CHROMA_DB_PERSIST_PATH}' ê²½ë¡œì™€ ì»¬ë ‰ì…˜ ì´ë¦„ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.error("ë°ì´í„°ê°€ ChromaDBì— ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ë ¤ë©´ 'load_movies_to_chromadb.py'ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤.")
        st.stop() # Streamlit ì•± ì¤‘ì§€

# ChromaDB ì»¬ë ‰ì…˜ ë¡œë“œ
chroma_collection = load_chroma_collection()

# OpenAI ì„ë² ë”© í•¨ìˆ˜ ì •ì˜
def get_openai_embeddings(texts, model=OPENAI_EMBEDDING_MODEL, max_retries=3, delay=1):
    """
    OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ì˜ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤.
    Rate Limit ë“±ìœ¼ë¡œ ì¸í•œ ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ ë¡œì§ í¬í•¨.
    """
    for i in range(max_retries):
        try:
            response = openai.embeddings.create(input=texts, model=model)
            return [d.embedding for d in response.data]
        except openai.APIStatusError as e:
            if e.status == 429:
                st.warning(f"OpenAI API Rate Limit ì´ˆê³¼ (ì¬ì‹œë„ {i+1}/{max_retries}). {delay}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                time.sleep(delay)
                delay *= 2 
            else:
                st.error(f"OpenAI API ì˜¤ë¥˜ ë°œìƒ: {e}")
                raise 
        except Exception as e:
            st.error(f"ì„ë² ë”© ìƒì„± ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise 
    raise Exception(f"ì˜¤ë¥˜: OpenAI ì„ë² ë”© ìƒì„± ì‹¤íŒ¨ í›„ {max_retries}ë²ˆ ì¬ì‹œë„.")

# ChromaDB ê²€ìƒ‰ í•¨ìˆ˜
def search_similar_movies_in_chroma(user_query, collection, top_k=5):
    """
    ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ì„ë² ë”©í•˜ê³  ChromaDBì—ì„œ ìœ ì‚¬í•œ ì˜í™”ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    """
    try:
        query_embedding = get_openai_embeddings([user_query], model=OPENAI_EMBEDDING_MODEL)[0]
        
        results = collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k,                     
            include=['metadatas', 'distances']   
        )
        
        if results and results['metadatas'] and len(results['metadatas'][0]) > 0:
            similar_movies = []
            for i in range(len(results['metadatas'][0])):
                movie_metadata = results['metadatas'][0][i]
                similar_movies.append(movie_metadata)
            return pd.DataFrame(similar_movies)
        else:
            return pd.DataFrame()
            
    except Exception as e:
        st.error(f"ì˜í™” ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame()

# GPT ë‹µë³€ ìƒì„± í•¨ìˆ˜
def generate_gpt_response(user_query, recommended_movies_df):
    """
    ì¶”ì²œëœ ì˜í™” ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ GPT ëª¨ë¸ì—ê²Œ ë‹µë³€ì„ ìƒì„±í•˜ë„ë¡ ìš”ì²­í•©ë‹ˆë‹¤.
    ë§Œì•½ ì¶”ì²œ ì˜í™” ì •ë³´ê°€ ì—†ìœ¼ë©´ GPT ëª¨ë¸ì˜ ì¼ë°˜ ì§€ì‹ì„ í™œìš©í•©ë‹ˆë‹¤.
    """
    if recommended_movies_df.empty:
        # ChromaDBì—ì„œ ê´€ë ¨ ì˜í™”ë¥¼ ì°¾ì§€ ëª»í–ˆì„ ê²½ìš° GPTì—ê²Œ ì§ì ‘ ì§ˆë¬¸í•©ë‹ˆë‹¤.
        print(f"DEBUG: ChromaDBì—ì„œ '{user_query}'ì— ëŒ€í•œ ì˜í™”ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. GPTì— ì§ì ‘ ë¬¸ì˜í•©ë‹ˆë‹¤.") # ë””ë²„ê¹…ìš©
        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì˜í™” ê´€ë ¨ ì§ˆë¬¸ì— ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëª¨ë¥´ëŠ” ë‚´ìš©ì€ ì†”ì§í•˜ê²Œ ëª¨ë¥¸ë‹¤ê³  ë§í•´ì£¼ì„¸ìš”."},
            {"role": "user", "content": user_query} # ì‚¬ìš©ì ì§ˆë¬¸ì„ ì§ì ‘ GPTì—ê²Œ ì „ë‹¬
        ]
    else:
        # ChromaDBì—ì„œ ê´€ë ¨ ì˜í™”ë¥¼ ì°¾ì•˜ì„ ê²½ìš°, í•´ë‹¹ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
        movie_info_strings = []
        for idx, row in recommended_movies_df.iterrows():
            info = f"ì œëª©: {row['title']}\n" \
                   f"ì¥ë¥´: {row['genres']}\n" \
                   f"ê°ë…: {row['directors']}\n" \
                   f"ì£¼ìš” ë°°ìš°: {row['actors']}\n" \
                   f"ì¤„ê±°ë¦¬: {row['overview']}\n" \
                   f"ê°œë´‰ì¼: {row['release_date']}\n" \
                   f"í‰ì : {row['vote_average']}/10\n"
            movie_info_strings.append(info)
        
        prompt = fr"""ì‚¬ìš©ì ì§ˆë¬¸: "{user_query}"

ë‹¤ìŒì€ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì˜í™” ì •ë³´ì…ë‹ˆë‹¤:

---
{'-'*50}
{"\n---\n".join(movie_info_strings)}
{'-'*50}

ìœ„ ì˜í™” ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•˜ë©° ì˜í™”ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”.
ë‹¨, ë‹¤ìŒê³¼ ê°™ì€ ê·œì¹™ì„ ì§€ì¼œì£¼ì„¸ìš”:
1. ì¶”ì²œí•˜ëŠ” ì˜í™”ì˜ 'ì œëª©', 'ì¥ë¥´', 'ê°ë…', 'ì£¼ìš” ë°°ìš°', 'ì¤„ê±°ë¦¬','í‰ì 'ì„ ê°„ëµí•˜ê²Œ ì–¸ê¸‰í•´ì£¼ì„¸ìš”.
2. ì¹œê·¼í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
3. ì˜í™” ì •ë³´ë¥¼ ê³¼ë„í•˜ê²Œ ìì„¸íˆ ì„¤ëª…í•˜ê¸°ë³´ë‹¤ëŠ” í•µì‹¬ì ì¸ ì •ë³´ë§Œ í¬í•¨í•´ì£¼ì„¸ìš”.
4. ì‚¬ìš©ì ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” ê²ƒì²˜ëŸ¼ ë³´ì´ë„ë¡ í•´ì£¼ì„¸ìš”.
5. ì˜í™” ì¶”ì²œ ì™¸ì— ë‹¤ë¥¸ ì§ˆë¬¸ì—ëŠ” 'ì €ëŠ” ì˜í™” ì¶”ì²œì— íŠ¹í™”ëœ ì±—ë´‡ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì€ ë„ì™€ë“œë¦¬ê¸° ì–´ë µìŠµë‹ˆë‹¤.'ë¼ê³  ë‹µë³€í•´ì£¼ì„¸ìš”.
6. ì¶”ì²œí•˜ëŠ” ì˜í™”ë¥¼ ì•Œë ¤ì¤„ ë•Œ ê¸€ì”¨ë¥¼ ë¹¼ê³¡í•˜ê²Œ ë‚˜ì—´ë§Œ í•˜ì§€ë§ê³  ê¹”ë”í•œ í˜•ì‹ìœ¼ë¡œ ì•Œë ¤ì£¼ì„¸ìš”.
"""
        messages = [
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì˜í™” ì¶”ì²œ ì „ë¬¸ê°€ ì±—ë´‡ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ì œê³µëœ ì˜í™” ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¹œì ˆí•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ì˜í™” ì¶”ì²œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ]

    try:
        response = openai.chat.completions.create(
            model=GPT_MODEL, 
            messages=messages,
            max_tokens=500, 
            temperature=0.7 
        )
        return response.choices[0].message.content
    except openai.APIError as e:
        st.error(f"OpenAI GPT API ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì˜í™” ì¶”ì²œ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    except Exception as e:
        st.error(f"ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ ìš”ì²­ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

# ì§ˆë¬¸ ì˜ë„ ë¶„ë¥˜ í•¨ìˆ˜
def classify_query_intent(user_query, gpt_model=GPT_MODEL, max_retries=3, delay=1):
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì´ ì˜í™” ì¶”ì²œ ê´€ë ¨ ì§ˆë¬¸ì¸ì§€ ë¶„ë¥˜í•©ë‹ˆë‹¤.
    """
    classification_prompt = f"""ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ì´ ì˜í™”, ë“œë¼ë§ˆ, ë˜ëŠ” íŠ¹ì • ì‘í’ˆ ì •ë³´ ìš”ì²­ê³¼ ê´€ë ¨ ìˆëŠ”ì§€ ì—†ëŠ”ì§€ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.
ì¦‰, **ì‚¬ìš©ìê°€ ì˜í™”ë‚˜ ë“œë¼ë§ˆë¥¼ ì°¾ê±°ë‚˜, íŠ¹ì • ì˜í™”/ë“œë¼ë§ˆì— ëŒ€í•œ ì •ë³´ë¥¼ ë¬»ëŠ” ì§ˆë¬¸**ì´ë©´ 'ì˜í™”ì¶”ì²œ'ìœ¼ë¡œ ë¶„ë¥˜í•˜ê³ ,
**ê·¸ ì™¸ì˜ ì§ˆë¬¸ (ì˜ˆ: ë‚ ì”¨, ì¼ë°˜ ìƒì‹, ê°œì¸ì ì¸ ì§ˆë¬¸ ë“±)**ì´ë©´ 'ê¸°íƒ€ì§ˆë¬¸'ìœ¼ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.
ëª…í™•í•˜ê²Œ 'ì˜í™”ì¶”ì²œ' ë˜ëŠ” 'ê¸°íƒ€ì§ˆë¬¸' ì¤‘ í•˜ë‚˜ë§Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ì§ˆë¬¸: "{user_query}"

ë¶„ë¥˜:"""

    messages = [
        {"role": "system", "content": "ì‚¬ìš©ì ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ 'ì˜í™”ì¶”ì²œ' ë˜ëŠ” 'ê¸°íƒ€ì§ˆë¬¸' ì¤‘ í•˜ë‚˜ë¡œë§Œ ë¶„ë¥˜í•˜ëŠ” AIì…ë‹ˆë‹¤. ì˜í™” ë° ë“œë¼ë§ˆ ê´€ë ¨ ì§ˆë¬¸ì€ ëª¨ë‘ 'ì˜í™”ì¶”ì²œ'ìœ¼ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤."}, 
        {"role": "user", "content": classification_prompt}
    ]

    for i in range(max_retries):
        try:
            response = openai.chat.completions.create(
                model=gpt_model,
                messages=messages,
                max_tokens=10, 
                temperature=0.0 
            )
            classification = response.choices[0].message.content.strip()
            print(f"ì§ˆë¬¸ '{user_query}' ë¶„ë¥˜ ê²°ê³¼: {classification}") 
            
            if "ì˜í™”ì¶”ì²œ" in classification.lower(): 
                return "ì˜í™”ì¶”ì²œ"
            elif "ê¸°íƒ€ì§ˆë¬¸" in classification.lower(): 
                return "ê¸°íƒ€ì§ˆë¬¸"
            else: 
                print(f"ê²½ê³ : GPTê°€ ì˜ˆìƒì¹˜ ëª»í•œ ë¶„ë¥˜ ê²°ê³¼ë¥¼ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤: '{classification}'. 'ê¸°íƒ€ì§ˆë¬¸'ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
                return "ê¸°íƒ€ì§ˆë¬¸"
                
        except openai.APIError as e:
            if e.status == 429:
                st.warning(f"ë¶„ë¥˜ API Rate Limit ì´ˆê³¼ (ì¬ì‹œë„ {i+1}/{max_retries}). {delay}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                time.sleep(delay)
                delay *= 2
            else:
                st.error(f"OpenAI API (ë¶„ë¥˜) ì˜¤ë¥˜ ë°œìƒ: {e}")
                return "ê¸°íƒ€ì§ˆë¬¸" 
        except Exception as e:
            st.error(f"ì§ˆë¬¸ ë¶„ë¥˜ ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return "ê¸°íƒ€ì§ˆë¬¸" 

# streamlit UI
st.set_page_config(page_title="ì˜í™” ì¶”ì²œ ì±—ë´‡", layout="centered")
st.title("ğŸ¬ ì˜í™” ì¶”ì²œ ì±—ë´‡")
st.markdown("ê¶ê¸ˆí•œ ì˜í™”ë‚˜ ë³´ê³  ì‹¶ì€ ì˜í™” ìŠ¤íƒ€ì¼ì„ ì•Œë ¤ì£¼ì„¸ìš”!")

if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.messages.append({"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ì–´ë–¤ ì˜í™”ë¥¼ ì°¾ìœ¼ì‹œë‚˜ìš”? ì €ëŠ” ì˜í™” ì¶”ì²œì— íŠ¹í™”ëœ ì±—ë´‡ì…ë‹ˆë‹¤."})

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if user_query := st.chat_input("ë³´ê³  ì‹¶ì€ ì˜í™” ìŠ¤íƒ€ì¼ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    # ì‚¬ìš©ì ë©”ì‹œì§€ í™”ë©´ì— ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": user_query})
    with st.chat_message("user"):
        st.markdown(user_query)

    # ì±—ë´‡ ì‘ë‹µ ìƒì„± ë° í‘œì‹œ
    with st.chat_message("assistant"):
        with st.spinner("ì§ˆë¬¸ ì˜ë„ë¥¼ íŒŒì•…í•˜ê³  ì˜í™” ì¶”ì²œ ì •ë³´ë¥¼ íƒìƒ‰í•˜ê³  ìˆì–´ìš”..."):
            # ì§ˆë¬¸ ì˜ë„ ë¶„ë¥˜
            intent = classify_query_intent(user_query, gpt_model=GPT_MODEL)
            
            if intent == 'ì˜í™”ì¶”ì²œ':
                recommended_movies_df = search_similar_movies_in_chroma(user_query, chroma_collection, top_k=3)
                gpt_response = generate_gpt_response(user_query, recommended_movies_df)
            else:
                gpt_response = "ì €ëŠ” ì˜í™” ì¶”ì²œì— íŠ¹í™”ëœ ì±—ë´‡ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì€ ë„ì™€ë“œë¦¬ê¸° ì–´ë µìŠµë‹ˆë‹¤."
            
            st.markdown(gpt_response)
            st.session_state.messages.append({"role": "assistant", "content": gpt_response})