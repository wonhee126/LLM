{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e78cafaf-a654-4cab-9628-24b8b46059b4",
   "metadata": {},
   "source": [
    "### **LLM API 활용해보기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c74bf5-c0af-423a-ae55-79bf5306e435",
   "metadata": {},
   "source": [
    "**[앤트로픽의 Claude 2.1 모델 API 호출 코드]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ecab962-27cd-4c1f-8879-a5086c0590ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import anthropic\n",
    "\n",
    "# anthropic.Anthropic(\n",
    "#     api_key=\"YOUR_API_KEY\").messages.create(\n",
    "#     model=\"claude-3-haiku-20240307\",\n",
    "#     max_tokens=1024,\n",
    "#     messages=[\n",
    "#         {\"role\": \"user\", \"content\": \"Hello, world\"}\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb304f-6908-4d04-b464-d09089c4b2bd",
   "metadata": {},
   "source": [
    "**[오픈AI의 GPT-3.5 Turbo 모델 API 호출 코드]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a391b0ea-9636-4d30-b8ff-d76a52b249f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-BlX89MeaFWULRQLzCoSslRytglr95', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"The Los Angeles Dodgers won the World Series in 2020. They defeated the Tampa Bay Rays to claim the championship, marking the Dodgers' first World Series title since 1988.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1750668469, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_34a54ae93c', usage=CompletionUsage(completion_tokens=37, prompt_tokens=17, total_tokens=54, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"\")\n",
    "client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"Who won the world series in 2020?\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fe2de7-faab-4c54-ad3c-b3a71a94a3cb",
   "metadata": {},
   "source": [
    "**[랭체인을 활용한 앤트로픽 Claude 2.1 모델 API 호출 코드]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aad9577c-fc84-4b12-ae0a-ae92b8cea8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_anthropic import ChatAnthropic \n",
    "# chat = ChatAnthropic(\n",
    "#     model_name=\"claude-3-haiku-20240307\",\n",
    "#     anthropic_api_key=\"YOUR_API_KEY\"\n",
    "# )\n",
    "# chat.invoke(\"안녕~ 너를 소개해줄래?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e54ca7-bf12-466a-a953-48be864995ec",
   "metadata": {},
   "source": [
    "**[랭체인을 활용한 오픈AI GPT-3.5 Turbo 모델 API 호출 코드]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "996168c5-989e-4b41-81d5-711b7e49c114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요! 저는 OpenAI에서 개발한 AI 언어 모델이에요. 텍스트 기반의 질문에 답하거나, 다양한 주제에 대해 대화할 수 있는 능력을 가지고 있어요. 정보 제공, 글쓰기, 학습 도우미 등 여러 가지 용도로 활용될 수 있습니다. 궁금한 점이나 이야기하고 싶은 주제가 있다면 언제든지 말씀해 주세요!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 82, 'prompt_tokens': 17, 'total_tokens': 99, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BlX8JWFRk5XVpPFAD5dcSVrlpnxqr', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c25c589e-45d4-4b01-9961-94806c4c4962-0', usage_metadata={'input_tokens': 17, 'output_tokens': 82, 'total_tokens': 99, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "chat = ChatOpenAI(\n",
    "    model_name='gpt-4o-mini',\n",
    "    openai_api_key=\"\"\n",
    ")\n",
    "chat.invoke(\"안녕~ 너를 소개해줄래?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9686342b-2d87-41f7-984d-0ffb2de72aa2",
   "metadata": {},
   "source": [
    "### **프롬프트 템플릿에 대해 알아보기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf60921-0b5e-45c8-96e9-3186b0128738",
   "metadata": {},
   "source": [
    "**[ChatPromptTemplate]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18f20b43-e6f2-4030-9be5-d02b5166862d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful AI bot. Your name is Bob.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hello, how are you doing?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"I'm doing well, thanks!\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What is your name?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "\t#SystemMessage: 유용한 챗봇이라는 역할과 이름을 부여\n",
    "        (\"system\", \"You are a helpful AI bot. Your name is {name}.\"), \n",
    "    #HumanMessage와 AIMessage: 서로 안부를 묻고 답하는 대화 히스토리 주입\n",
    "        (\"human\", \"Hello, how are you doing?\"),\n",
    "        (\"ai\", \"I'm doing well, thanks!\"),\n",
    "    #HumanMessage로 사용자가 입력한 프롬프트를 전달\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(name=\"Bob\", user_input=\"What is your name?\")\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f21ed911-2667-4c9a-90e4-c8be4e07c063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content=\"You are a helpful assistant that re-writes the user's text to sound more upbeat.\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"I don't like eating tasty things\", additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "       \"You are a helpful assistant that re-writes the user's text to sound more upbeat.\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")\n",
    "messages = chat_template.format_messages(text=\"I don't like eating tasty things\")\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e227bd0b-17fb-457f-86a5-97d8a83676b3",
   "metadata": {},
   "source": [
    "### **LLM API의 다양한 기능 활용해보기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bd8ae6-4c55-4700-a466-d0dfbb5371f8",
   "metadata": {},
   "source": [
    "**[LLM API의 Temperature 이애하기]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08240f98-37f0-48ef-ac6d-78e68561c121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      ">>> 파이썬은 간결하고 읽기 쉬운 문법, 다양한 라이브러리와 프레임워크, 그리고 데이터 과학, 웹 개발, 인공지능 등 다양한 분야에서의 활용성 덕분에 가장 인기 있는 프로그래밍 언어로 자리잡았습니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      ">>> 파이썬은 간결하고 읽기 쉬운 문법, 다양한 라이브러리와 프레임워크, 그리고 데이터 과학, 웹 개발, 인공지능 등 다양한 분야에서의 활용성 덕분에 가장 인기 있는 프로그래밍 언어로 자리잡았습니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      ">>> 파이썬은 간결하고 이해하기 쉬운 문법, 풍부한 라이브러리, 다양한 분야에서의 적용 가능성 덕분에 가장 인기 있는 프로그래밍 언어로 자리잡았습니다.\n",
      "----------------------------------------------------------------------------------------------------\n",
      ">>> 파이썬은 간결한 문법과 다양한 라이브러리 덕분에 배우기 쉽고, 웹 개발, 데이터 분석, 인공지능 등 다양한 분야에서 널리 사용되어 인기가 높습니다.\n"
     ]
    }
   ],
   "source": [
    "#API KEY 저장을 위한 os 라이브러리 호출\n",
    "import os\n",
    "\n",
    "#OPENAI API키 저장\n",
    "os.environ[\"OPENAI_API_KEY\"]=\"\"\n",
    "\n",
    "#Temperature=0\n",
    "chatgpt_temp0_1 = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature = 0)\n",
    "chatgpt_temp0_2 = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature = 0)\n",
    "\n",
    "#Temperature=1\n",
    "chatgpt_temp1_1 = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature = 1)\n",
    "chatgpt_temp1_2 = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature = 1)\n",
    "\n",
    "model_list = [chatgpt_temp0_1, chatgpt_temp0_2, chatgpt_temp1_1, chatgpt_temp1_2]\n",
    "\n",
    "for i in model_list:\n",
    "    answer = i.invoke(\"왜 파이썬이 가장 인기있는 프로그래밍 언어인지 한 문장으로 설명해줘\", max_tokens = 128)\n",
    "    print(\"-\"*100)\n",
    "    print(\">>>\",answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a8bf0d-b183-4407-819d-73555754104e",
   "metadata": {},
   "source": [
    "**[ChatGPT처럼 답변 스트리밍하기]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc1a6d34-1c73-4b6e-b6f9-0141dec03eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "달빛이 비추는 고요한 밤  \n",
      "은은한 빛으로 세상을 감싸네  \n",
      "하늘의 별들과 속삭이며  \n",
      "그림자 속에 숨은 꿈을 찾아\n",
      "\n",
      "구름 사이로 얼굴을 내밀고  \n",
      "소중한 비밀을 나에게 전해  \n",
      "어둠 속에서도 빛나는 너  \n",
      "내 마음의 등불, 달아, 너여\n",
      "\n",
      "너의 미소는 바다를 비추고  \n",
      "사랑의 노래를 부르는 듯  \n",
      "그리움이 가득한 이 밤에  \n",
      "너와 나, 영원히 함께하길\n",
      "\n",
      "달이여, 나의 친구여  \n",
      "너의 품에 안겨 잠들고 싶어  \n",
      "세상의 모든 슬픔을 잊고  \n",
      "너와 함께하는 이 순간이 영원하길."
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "chat = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature = 0)\n",
    "for chunk in chat.stream(\"달에 관한 시를 써줘\"):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47973815-82d8-4226-bb03-1f18b4d535f6",
   "metadata": {},
   "source": [
    "**[답변 캐싱하기]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21a83d7d-e566-4bb0-8b6f-dc172f29afb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache #캐시메모리 라이브러리 호출\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5ab26d-d085-4188-b740-bb295dda6a92",
   "metadata": {},
   "source": [
    "**첫 질문-응답 시간 측정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0d9b3ab-70cf-47d5-817f-b13dcdbd1d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time \n",
    "# #셀 실행 시간 측정\n",
    "# from langchain.cache import InMemoryCache\n",
    "# set_llm_cache(InMemoryCache()) #캐시메모리 설정\n",
    "\n",
    "# chat.invoke(\"일반상대성 이론을 한마디로 설명해줘\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a1442a-7cb7-44be-87e3-a0d92c86df33",
   "metadata": {},
   "source": [
    "**두번째 질문-응답 시간 측정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f76c2ac9-ce6c-4c4b-9147-6c75291c2ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 3.64 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='일반상대성 이론은 중력이 시공간의 곡률로 설명되며, 질량이 큰 물체가 주변의 시공간을 휘게 만들어 다른 물체의 운동에 영향을 미친다는 이론입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 22, 'total_tokens': 75, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-BlX8Y9p5VPG3D4cq2RWCG4jmHwTwg', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--241fb869-b996-4295-889e-fdc9e7baaa10-0', usage_metadata={'input_tokens': 22, 'output_tokens': 53, 'total_tokens': 75, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#같은 질문 전달\n",
    "chat.invoke(\"일반상대성 이론을 한마디로 설명해줘\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4d108f-899d-46aa-9a35-1ff6f38c8d8e",
   "metadata": {},
   "source": [
    "### **실습**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c333eb-b5ac-441b-a968-4eb2e2930061",
   "metadata": {},
   "source": [
    "**[이번 장에서 배운 것 실습해보기] - 스트리밍되는 AI스터디 플래너 챗봇 만들기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17a26848-d9b2-4520-b0db-61e77d5e9c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large Language Model(LLM)에 대한 공부 계획을 세워드리겠습니다. 이 계획은 4주 동안 진행되며, 매주 주제를 나누어 학습할 수 있도록 구성하였습니다.\n",
      "\n",
      "### 1주차: LLM의 기초 이해\n",
      "- **목표**: LLM의 기본 개념과 역사 이해\n",
      "- **학습 내용**:\n",
      "  - LLM의 정의 및 작동 원리\n",
      "  - 자연어 처리(NLP)의 기초\n",
      "  - LLM의 발전 과정 (예: GPT, BERT 등)\n",
      "- **추천 자료**:\n",
      "  - 온라인 강의: Coursera, edX의 NLP 기초 강의\n",
      "  - 관련 논문: \"Attention is All You Need\" (Transformer 모델 소개)\n",
      "- **활동**:\n",
      "  - LLM의 발전 역사에 대한 요약 작성\n",
      "  - 주요 용어 정리 (예: Tokenization, Embedding 등)\n",
      "\n",
      "### 2주차: LLM의 구조와 기술\n",
      "- **목표**: LLM의 구조와 기술적 요소 이해\n",
      "- **학습 내용**:\n",
      "  - Transformer 아키텍처의 구성 요소 (Self-Attention, Feedforward Network 등)\n",
      "  - Pre-training과 Fine-tuning 과정\n",
      "  - LLM의 학습 방법 (지도 학습, 비지도 학습)\n",
      "- **추천 자료**:\n",
      "  - \"The Illustrated Transformer\" 블로그 포스트\n",
      "  - 관련 강의: Stanford CS224N (NLP with Deep Learning)\n",
      "- **활동**:\n",
      "  - Transformer 구조를 시각적으로 그려보기\n",
      "  - Pre-training과 Fine-tuning의 차이점 정리\n",
      "\n",
      "### 3주차: LLM의 응용 및 사례\n",
      "- **목표**: LLM의 다양한 응용 사례 탐색\n",
      "- **학습 내용**:\n",
      "  - LLM을 활용한 텍스트 생성, 번역, 요약 등\n",
      "  - LLM의 실제 사용 사례 (예: ChatGPT, Google BERT)\n",
      "  - LLM의 한계와 윤리적 고려사항\n",
      "- **추천 자료**:\n",
      "  - 사례 연구: OpenAI의 GPT-3 사용 사례\n",
      "  - 관련 논문: \"Language Models are Few-Shot Learners\"\n",
      "- **활동**:\n",
      "  - LLM을 활용한 프로젝트 아이디어 구상\n",
      "  - LLM의 윤리적 문제에 대한 토론\n",
      "\n",
      "### 4주차: 실습 및 프로젝트\n",
      "- **목표**: LLM을 활용한 실습 및 프로젝트 진행\n",
      "- **학습 내용**:\n",
      "  - Hugging Face Transformers 라이브러리 사용법\n",
      "  - 간단한 LLM 모델 구축 및 실험\n",
      "  - 결과 분석 및 개선 방안 모색\n",
      "- **추천 자료**:\n",
      "  - Hugging Face 공식 문서 및 튜토리얼\n",
      "  - GitHub의 LLM 관련 오픈소스 프로젝트\n",
      "- **활동**:\n",
      "  - 간단한 LLM 모델을 구축하고 결과를 기록\n",
      "  - 프로젝트 결과 발표 및 피드백 받기\n",
      "\n",
      "### 추가 팁\n",
      "- 매주 학습한 내용을 정리하여 블로그나 노트에 기록하세요.\n",
      "- 관련 커뮤니티(예: Reddit, Stack Overflow)에 참여하여 질문하고 토론하세요.\n",
      "- 최신 연구 동향을 따라가기 위해 관련 논문을 정기적으로 읽는 습관을 들이세요.\n",
      "\n",
      "이 계획을 통해 LLM에 대한 깊이 있는 이해를 쌓을 수 있기를 바랍니다!"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "#GPT-3.5 모델 호출\n",
    "chat = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature = 0)\n",
    "\n",
    "#ChatPromptTemplate 통해 스터디 플래너 역할 부여 및 사용자 프롬프트 매개변수화\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"당신은 공부 계획을 세워주는 스터디 플래너 머신입니다.\"\n",
    "                \"사용자의 공부 주제를 입력 받으면, 이를 학습하기 위한 공부 계획을 작성합니다.\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#앞서 설정한 프롬프트 템플릿에 HumanMessage로 문장 전달\n",
    "messages = chat_template.format_messages(text=\"Large Language Model에 대해서 공부하고 싶어요.\")\n",
    "\n",
    "#stream 함수를 통해 답변 스트리밍\n",
    "for chunk in chat.stream(messages):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f79fe7-c008-41ca-8b82-25bd8a3164e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
